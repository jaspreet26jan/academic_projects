#twitter text Analysis
library(twitteR) 
library(ROAuth) 
require(RCurl) 
library(stringr) 
library(tm) 
library(ggmap)
library(plyr)
library(dplyr) 
library(tm) 
library(wordcloud)
key="hidden" 
secret="hidden" 
setwd("~/text_mining_and_web_scraping") 
download.file(url="http://curl.haxx.se/ca/cacert.pem", 
              destfile="~/text_mining_and_web_scraping", 
              method="auto") 

consumer_key <- "243hXrihCSkZooa2VrYONKtYK"
consumer_secret <- "au39q9OTb4LxdyM9qx0YR9ymn7noKkJhlMAedYhFXCoW6XW5ES"
access_token <- "631060814-vxQwGcw8FL1WDr4nkMrpBzNKCXp56dqXtvbu0onO"
access_secret <- "wBXJDZg41DAbNiEMdpzVq79OGrg1xqCzgoiakHdn3v8vB"
authenticate <- setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
save(authenticate, file="twitter authentication.Rdata")


# harvest some tweets 
some_tweets = searchTwitter("starbucks", n=1500, lang="en") 
# get the text 
some_txt = sapply(some_tweets, function(x) x$getText())

# remove retweet entities 
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt) 
# remove at people 
some_txt = gsub("@\\w+", "", some_txt) 
# remove punctuation 
some_txt = gsub("[[:punct:]]", "", some_txt)
# remove numbers 
some_txt = gsub("[[:digit:]]", "", some_txt) 
# remove html links 
some_txt = gsub("http\\w+", "", some_txt)
# remove unnecessary spaces 
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt) 
# define "tolower error handling" function
try.error = function(x) { 
  # create missing value 
  y = NA 
  # tryCatch error 
  try_error = tryCatch(tolower(x), error=function(e) e) 
  # if not an error 
  if (!inherits(try_error, "error")) 
    y = tolower(x)
  # result 
  return(y) } 
# lower case using try.error with sapply 
some_txt = sapply(some_txt, try.error)

# remove NAs in some_txt 
some_txt = some_txt[!is.na(some_txt)] 
names(some_txt) = NULL

#classify emotion 
class_emo = classify_emotion(some_txt, algorithm="bayes", prior=1.0) 
# get emotion best fit 
emotion = class_emo[,7] # substitute NA's by "unknown" 
emotion[is.na(emotion)] = "unknown" # classify polarity 
class_pol = classify_polarity(some_txt, algorithm="bayes")
# get polarity best fit 
polarity = class_pol[,4]


# data frame with results 
sent_df = data.frame(text=some_txt, emotion=emotion, 
                     polarity=polarity, stringsAsFactors=FALSE)

# sort data frame 
sent_df = within(sent_df, 
                 emotion <- factor(emotion, levels=names(sort(table(emotion), 
                                                              decreasing=TRUE))))


# plot distribution of emotions 
ggplot(sent_df, aes(x=emotion)) + 
  geom_bar(aes(y=..count.., fill=emotion)) + 
  scale_fill_brewer(palette="Dark2") + 
  labs(x="emotion categories", y="number of tweets", title = "Sentiment Analysis of Tweets about Starbucks\n(classification by emotion)",
       plot.title = element_text(size=12))

# plot distribution of polarity 
ggplot(sent_df, aes(x=polarity)) + 
  geom_bar(aes(y=..count.., fill=polarity)) + 
  scale_fill_brewer(palette="RdGy") + 
  labs(x="polarity categories", y="number of tweets", title = "Sentiment Analysis of Tweets about Starbucks\n(classification by polarity)", 
       plot.title = element_text(size=12))


# separating text by emotion 
emos = levels(factor(sent_df$emotion)) 
nemo = length(emos) 
emo.docs = rep("", nemo) 
for (i in 1:nemo) { 
  tmp = some_txt[emotion == emos[i]] 
  emo.docs[i] = paste(tmp, collapse=" ") 
} # remove stopwords 
emo.docs = removeWords(emo.docs, stopwords("english"))
# create corpus 
corpus = Corpus(VectorSource(emo.docs)) 
tdm = TermDocumentMatrix(corpus) 
tdm = as.matrix(tdm) 
colnames(tdm) = emos 
# comparison word cloud 
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"), 
                 scale = c(3,.5), random.order = FALSE, title.size = 1.5)



N=2000 # tweets to request from each query 
S=200 # radius in miles 
lats=c(38.9,40.7,37.8,39,37.4,28,30,42.4,48,36,32.3,33.5,34.7,33.8,37.2,41.2,46.8, 46.6,37.2,43,42.7,40.8,36.2,38.6,35.8,40.3,43.6,40.8,44.9,44.9) 
lons=c(-77,-74,-122,-105.5,-122,-82.5,-98,-71,-122,-115,-86.3,-112,-92.3,-84.4,-93.3, -104.8,-100.8,-112, -93.3,-89,-84.5,-111.8,-86.8,-92.2,-78.6,-76.8,-116.2,-98.7,-123,-93)
#cities=DC,New York,San Fransisco,Colorado,Mountainview,Tampa,Austin,Boston,
# Seattle,Vegas,Montgomery,Phoenix,Little Rock,Atlanta,Springfield, 
# Cheyenne,Bisruk,Helena,Springfield,Madison,Lansing,Salt Lake City,Nashville
# Jefferson City,Raleigh,Harrisburg,Boise,Lincoln,Salem,St. Paul
donald=do.call(rbind,lapply(1:length(lats), function(i) 
  searchTwitter('Donald+Trump', lang="en",n=N,resultType="recent", 
                geocode=paste(lats[i],lons[i],paste0(S,"mi"),sep=",",Sys.sleep(10)))))

donaldlat=sapply(donald, function(x) as.numeric(x$getLatitude())) 
donaldlat=sapply(donaldlat, function(z) ifelse(length(z)==0,NA,z)) 

donaldlon=sapply(donald, function(x) as.numeric(x$getLongitude())) 
donaldlon=sapply(donaldlon, function(z) ifelse(length(z)==0,NA,z)) 

donalddate=lapply(donald, function(x) x$getCreated()) 
donalddate=sapply(donalddate,function(x) 
  strftime(x, format="%Y-%m-%d %H:%M:%S",tz = "UTC")) 

donaldtext=sapply(donald, function(x) x$getText()) 
donaldtext=unlist(donaldtext)

isretweet=sapply(donald, function(x) x$getIsRetweet())
retweeted=sapply(donald, function(x) x$getRetweeted()) 
retweetcount=sapply(donald, function(x) x$getRetweetCount())

favoritecount=sapply(donald, function(x) x$getFavoriteCount())


